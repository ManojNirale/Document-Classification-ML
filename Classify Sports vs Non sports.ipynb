{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os,glob\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = [(r'data/Train_data/Nonsports/', 'NONSPORTS'),\n",
    "          (r'data/Train_data/Sports/', 'SPORTS')\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_frame(fpath, label):\n",
    "    rows = []\n",
    "    for file_name in os.listdir(fpath):\n",
    "        path = os.path.join(fpath,file_name)\n",
    "        rows.append({'text': path, 'labels': label })\n",
    "    data_frame = pd.DataFrame(rows)\n",
    "    return(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'text': [], 'labels':[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nirale1.kumar\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "for dpath, classification in source:\n",
    "    data = data.append(build_data_frame(dpath, classification))\n",
    "#print(data)\n",
    "train = data['text'].values\n",
    "targets = data['labels'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,1),token_pattern=r'\\b\\w+\\b', min_df=2,lowercase=True, stop_words=\"english\",input='filename',decode_error='ignore', strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform((train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(X.A, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using multinomial Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.fit(X,targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'data/Test_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = []\n",
    "for path in glob.glob(test_path+'\\*.txt'):\n",
    "    text_data.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/Test_data\\\\NeW_non_sport.txt',\n",
       " 'data/Test_data\\\\Non_Sports16.txt',\n",
       " 'data/Test_data\\\\Sports1.txt',\n",
       " 'data/Test_data\\\\Sports2.txt',\n",
       " 'data/Test_data\\\\Sports3.txt',\n",
       " 'data/Test_data\\\\test1.txt',\n",
       " 'data/Test_data\\\\test2.txt']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = vectorizer.transform(text_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = clf.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NONSPORTS' 'NONSPORTS' 'SPORTS' 'SPORTS' 'SPORTS' 'SPORTS' 'NONSPORTS']\n"
     ]
    }
   ],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(zip(text_data,predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/Test_data\\\\NeW_non_sport.txt', 'NONSPORTS'),\n",
       " ('data/Test_data\\\\Non_Sports16.txt', 'NONSPORTS'),\n",
       " ('data/Test_data\\\\Sports1.txt', 'SPORTS'),\n",
       " ('data/Test_data\\\\Sports2.txt', 'SPORTS'),\n",
       " ('data/Test_data\\\\Sports3.txt', 'SPORTS'),\n",
       " ('data/Test_data\\\\test1.txt', 'SPORTS'),\n",
       " ('data/Test_data\\\\test2.txt', 'NONSPORTS')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    # Remove punctuations, digits and stop words\n",
    "    # Removal of repeated contents\n",
    "    valid_text=[]\n",
    "    stop = set(stopwords.words('english'))\n",
    "\n",
    "    for text in data:\n",
    "        words=re.findall(r'\\b[a-zA-Z][a-z]{2,9}\\b',text)\n",
    "        valid_words=[]\n",
    "        for word in words:\n",
    "            if word not in stop:\n",
    "                valid_words.append(word)\n",
    "        valid_text.append(' '.join(valid_words))\n",
    "    return valid_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train = [codecs.open(file,encoding='utf-8',errors='ignore').read() for file in data['text'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_labels = data['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clean_train = clean_data(my_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Indian economy appears absorbed twin shocks hasty Goods Services Tax course healthy growth medium term Economic Survey says listing quite parameters show economy healing The number indirect taxpayers per cent lakh new income tax filers coming forward year Besides large increase voluntary small per cent rise direct tax Therefore despite large scale disruption businesses economy general led greater wider tax net This surely good news Besides reversal decline exports revival meant gross domestic product estimates improved The Survey pegs current fiscal growth per cent ahead per cent Central Office estimated earlier And next fiscal growth set per cent India may become fastest growing economy planet Chief economic adviser Arvind taken incessant two numbers growth likely closer wisely There many much point sticking one neck precise'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clean_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_tfidf = tfidf_vectorizer.fit_transform((my_clean_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_tfidf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_tfidf = classifier_tfidf.fit(fit_tfidf,my_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on new test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test = [codecs.open(file,encoding='utf-8',errors='ignore').read() for file in text_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_clean = clean_data(my_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tfidf = tfidf_vectorizer.transform(my_test_clean).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tfidf = classifier_tfidf.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NONSPORTS' 'NONSPORTS' 'SPORTS' 'SPORTS' 'SPORTS' 'SPORTS' 'NONSPORTS']\n"
     ]
    }
   ],
   "source": [
    "print(predict_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_tfidf = list(zip(text_data,predict_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/Test_data\\\\NeW_non_sport.txt', 'NONSPORTS'),\n",
       " ('data/Test_data\\\\Non_Sports16.txt', 'NONSPORTS'),\n",
       " ('data/Test_data\\\\Sports1.txt', 'SPORTS'),\n",
       " ('data/Test_data\\\\Sports2.txt', 'SPORTS'),\n",
       " ('data/Test_data\\\\Sports3.txt', 'SPORTS'),\n",
       " ('data/Test_data\\\\test1.txt', 'SPORTS'),\n",
       " ('data/Test_data\\\\test2.txt', 'NONSPORTS')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
